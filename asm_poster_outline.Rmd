```{r requirements, echo = FALSE, message=FALSE, results='hide'}
##  Initial data processing 
#loading required packages and sourcing files
library(ggplot2)
library(stringr)
library(reshape2)
library(plyr)
library(xtable)
library(combinat)
source("purity_functions.R")
source("file_locations.R")
source("match_tid.R")

#loading single organisms datasets
single_matches <- read.csv(str_c(path_results_directory,c("/sim_single_matches.csv"), sep=""), stringsAsFactors = F)

#loading simualted contaminant datasets
contam_matches <- read.csv(str_c(path_results_directory,"/sim_contam_matches.csv", sep=""), stringsAsFactor = F)
for(i in c("org1_tid","org2_tid","size")){
  contam_matches[,i] <- as.factor(contam_matches[,i])
}
```
```{r org_names, echo=FALSE, message=FALSE}
org_tid <- unique(single_matches$org_tid)
org_name <- c()
#org_species <- c()
org_genus <- c()
for(i in org_tid){
  
  org_name <- c(org_name,python.call("getNameByTaxid", i))
  org_taxa <- GetTaxInfoLocal(i)
  org_taxa <- org_taxa[org_taxa$tid != 131567,]
  #org_species <- c(org_species, as.character(org_taxa$name[org_taxa$rank == "species"][1]))
  org_genus <- c(org_genus, as.character(org_taxa$name[org_taxa$rank == "genus"][1]))
}
org_df <- data.frame(org_tid, name = org_name, genus = org_genus) #species = org_species, 
org_table <- dcast(org_df,genus~.)
```
```{r contam-match-levels, echo=FALSE, message=FALSE}
#match table taxonomic names find lowest shared common taxonomic level
org_sets <- combn(as.numeric(levels(contam_matches$org1_tid)), m = 2, simplify=F)
org_taxa_share <- ldply(org_sets,function(x){GetMatchLevel(id1 =x[1], id2= x[2])})
org_taxa_share <- cbind(org_taxa_share, ldply(org_sets))
colnames(org_taxa_share) <- c("match", "org1_tid","org2_tid")
org_taxa_share2 <- data.frame(match = org_taxa_share$match, 
                              org1_tid = org_taxa_share$org2_tid,
                              org2_tid = org_taxa_share$org1_tid)
org_taxa_share <- rbind(org_taxa_share, org_taxa_share2)
```

```{r baselines, echo=FALSE, message=FALSE}
#baseline values
#from single matches get the Final.Guess values for the appropriate match level
#what are you defining as base line- max Final.Guess for each level
single_matches <- join(single_matches, org_df)
baseline <- ddply(single_matches, .(genus, match), summarize, min = min(Final.Guess), median = mean(Final.Guess),max = max(Final.Guess), p90 = quantile(Final.Guess, probs=0.9))
```


```{r}
#comparison of shared taxonomic levels, final guess- with contaminants
```
```{r}
# need to have read counts for the different org and contributions to the datasets
# parse the readId files and count the number of reads based on the NC_####
```


Outline for ASM poster on validating test material purity
========================================================
# Header
## Title   
Development of methods for using the pathoscope sequence analysis software to validate microbial test material purity.

## Authors  
Nathan D. Olson    
Justin Zook    
Jayne Morrow    
Nancy Lin 

## Author Affiliation  
Biosystems and Biomaterials Division, National Institute of Standards and Technology   

## Contact  
email nolson@nist.gov

# Abstract
Method validation for biodetection technologies requires high purity test materials.  Traditional methods for evaluating test material purity, e.g. polymerase chain reaction (PCR), require prior knowledge of the contaminant identity and have a limited level of detection (LOD).  Whole genome sequencing using next generation sequencing (NGS) technology addresses these limitations by providing a non-target specific approach and a lower LOD due to the large number of reads generated in a sequencing run – ten thousand to over one million reads.  Here we present a novel application of the pathoscope sequence analysis program (http://sourceforge.net/projects/pathoscope/) coupled with an expanded reference dataset to evaluate test material purity and validate material identity using simulated whole genome sequencing datasets.  To evaluate the ability of pathoscope to identify contaminants in test materials, in silico generated datasets for `r length(unique(single_matches$input_filename))` organisms from `r length(unique(org_df$genus))` different genera (`r unique(org_df$genus)`).   First, the results from the analysis of the single organism datasets using pathoscope served as a baseline for the simulated contaminat analysis. To determine the method LOD, simulated reads from `r length(unique(contam_matches$org2))` were mixed at known proportions. **Need to revise** *All contaminant organisms were detected to proportions of at least 1 in 100, and P. aeruginosa and S. aureus were detectable as contaminants in all target organisms down to proportions of 1 in 10$^7$.*  The approach presented here provides a sample independent, highly sensitive, and specific method for evaluating test material purity.  With the rapid decrease in NGS costs, this approach is a viable alternative to PCR based methods for evaluating test material purity and can be applied in a high throughput manner for screening panels of test materials used to validate biothreat detection technologies.   

# Introduction
*Need new background introduction paragraph*     
There are a number of potential sources for contamination of test materials with other microorganisms, including the stock culture, the preservation medium, as well as airborne and laboratory contaminants.  While high levels of contamination may be more easily identified, a rigorous and systematic approach is often needed to detect lower levels of contamination.  For example, a purified culture of Geobacter sulfurreducens strain KN400 over 20 years old was found to have low levels of contamination of Geobacter sulfurreducens strain DL1 [8].   However, the KN400 genome was sequenced using next–generation sequencing with 80 X coverage without identification of the contaminant.  The contaminant was first detected using a selective culturing system.  After initial identification of the contaminant, the concentration of the contaminant was determined using polymerase chain reaction (PCR) and next generation sequencing for the OmcS gene, which contained a 14 bp difference between the contaminant and culture strain.  From the PCR assay, the contaminant was determined to contribute 1 out of 105 copies of the OmcS gene with the remainder of the copies contributed by the main KN400 strain.  Once the contaminant was identified, a systematic approach could then be used to identify the source of the contaminant, if desired. 
Current methods for evaluating test material purity include PCR-based assays, metagenomics, and whole genome sequencing based approaches.  One PCR assay was developed to analyze protist cultures.  This PCR assay uses endpoint PCR for prokaryotes and eukaryotes with template dilutions [9].  The benefit to PCR-based approaches is that they can be cost effective and fast if an applicable protocol exists.   However, PCR assays can only target specific contaminants.  While PCR based assays can detect contaminants, this approach does not scale effectively for multiple, potentially unknown contaminants and test materials.   
The bioinformatics tools developed to identify contaminants in metagenomic datasets, which include sequencing data from all organisms in a sample, can also be used to evaluate test material purity.  For example DeconSeq [10] and a similar method QC-Chain [11] were developed to identify contaminants based on analysis of 16S ribosomal ribonucleic acid (rRNA) gene sequences or comparison of a subset of reads to a reference database using Basic local alignment search tool (BLAST).  Metagonomic-based methods such as these are able to identify contaminants without any prior knowledge or assumptions regarding the identity of the organism(s).  However, methods based on 16S rRNA gene identification have limited resolution, as 16S rRNA sequences can only provide genus level taxonomic resolution at best.  Methods using BLAST-based searches represent a broader scale approach but are limited by the accuracy of the BLAST classification method.   The benefit to using tools developed for metagenomics is that prior knowledge of the identity of the contaminant is not required; however this method is unable to identify contaminants to the strain level.   
Another approach to evaluating test material purity is through shotgun whole genome sequencing, which attempts to sequence all DNA in a sample.  A recently published bioinformatics method, pathoscope, was developed to detect pathogens and identify strains using whole genome sequencing data.  This method benefits from the large sample size obtained using next generation sequencing for higher sensitivity and leverages algorithm advances for whole genome sequence mapping.  Mapping algorithms determine the optimal placement of reads relative to a reference sequence.  Reads are either uniquely or ambiguously mapped.  For uniquely mapped reads only a single optimal mapping location is identified, whereas for ambiguously mapped reads multiple optimal mapping locations are identified.  Pathoscope uses the number of reads that uniquely map to different genomes in the reference database to assign ambiguously mapped reads, reads that align equally well to multiple reference sequences.  The primary benefits to the shotgun whole genome sequencing and subsequent pathoscope analysis approach are that prior knowledge of the contaminant is not required and it can potentially identify the contaminant to the strain level.  However, the main limitation to this method is the size of the reference database, namely that the genome of the contaminant or a closely related organism must be present in the database for the contaminant to be detected.
Robust approaches to measure purity of microbial test materials used to validate biothreat detection assays will provide an increased confidence in the results from those assays.  In this work, we developed a novel method to measure the purity of single organism test materials.  This method is based on whole genome sequencing and utilizes pathoscope with an expanded reference database [12].  We will first present the specificity of the method using simulated data for single organisms.  Then, we will evaluate the limit of detection and quantitative accuracy of the method using simulated datasets generated to represent test materials contaminated at various levels.  


# Methods
This bioinformatics approach to measuring test material purity consists of three steps.   
1. Sequencing reads are generated for the test material using shotgun sequencing.   
2. The reads are mapped to a reference database.  
        For this step individual reads are aligned to all possible locations in the genomes in the reference database.   We generated a more exhaustive database compared to the pathoscope database including all prokaryotic organisms in the Genbank database (http://www.ncbi.nlm.nih.gov/genbank/, accessed 10/18/2013).    
3. The resulting mapping file is processed with pathoscope to assess dataset composition [12].
        For the mapping step the bwa mem mapping algorithm was used (http://bio-bwa.sourceforge.net).  This algorithm is capable of mapping reads to reference databases greater than 4 Gb in size.  The reference dataset included the chromosomes and plasmids for 2,709 bacterial genomes, including the strains used to validate the procedure.  Additionally, bwa mem can output all possible alignments for ambiguously mapped reads.  

To evaluate the specificity and sensitivity of the approach, simulated single organism as well as contaminated datasets (mixtures of two organisms) were generated.  The organisms used in the study included common biothreat agents and foodborne human pathogens (Table 1).  Simulated datasets were generated using the ART sequencing read simulator (Reference for ART).  The ART simulator used error models based on real sequence datasets to generate more realistic datasets.  The datasets were generated using the Illumina error models with paired end 75 and 250 base pair reads and 20 X mean coverage for each of the strains [13].

Simulated whole genome sequencing datasets for `r length(unique(single_matches$input_filename))` organisms from  `r length(unique(org_df$genus))` different genus (Table 1) were used to evaluate the method specificity. Datasets from the individual organisms were mapped to the all-bacterial genomes database using bwa mem.  The resulting mapping file was processed using pathoscope.  The specificity of the individual organisms was evaluated at the strain to phylum level.
```{r genus-table, results='asis', echo=FALSE}
colnames(org_table) <- c("Genus", "Strains")
org_table$Genus <- as.character(org_table$Genus)
org_table2 <- rbind(org_table, c(Genus = "Total", Strains = sum(org_table$Strains)))
print(xtable(org_table2),type='html')
```

```{r proportions, echo=FALSE, results='hide'}
## contaminat proportions
proportions <- str_c(unique(contam_matches$prop1),signif(1 - unique(contam_matches$prop1),2), sep = ":")
```

To evaluate the method sensitivity, simulated datasets with a target strain and a contaminant strain were generated and evaluated.  The reads in the datasets were subsampled in the following proportions:`r proportions[-1]` and `r proportions[length(proportions)]` where the first number represents the percentage of reads randomly selected from the target organism dataset and the second number represents the number of reads randomly selected from the contaminant dataset.  For example, a proportion of 0.5:0.5, the combined dataset included a random subsampling of 50 % of the reads from the target organism dataset and 50 % of the reads from the contaminant organism dataset.  Datasets were generated for all pairwise comparisons so that each of the six organisms was both a contaminant and target organism for all possible combinations at all 9 proportions, for a total of `r length(unique(contam_matches$input_filename))`  combinations.  The individual organism datasets vary in the number of reads in the due to differences in genome size, such that 50 % of one dataset will be a different absolute number of reads than 50 % of another dataset.   
To generate the simulated mapping datasets, the mapping files for the individual organisms were merged using samtools (http://samtools.sourceforge.net).  The resulting merged data files were downsampled to obtain the appropriate proportions of organisms for each of the `r length(unique(contam_matches$input_filename))` combinations using an in-house python script.  The resulting simulated contaminated datasets were processed using pathoscope, and the output files were analyzed to determine the limit of detection and quantitative accuracy of the methods using the statistical programing language R [14].

All of the scripts used in the study are available at https://github.com/nate-d-olson/genomic_purity. 

# Results and Discussion
## Specificity
```{r }
unique_count_plot(single_matches)
```
For all organisms the number of unqiue matches decreases with increase in the length of the simulated reads. 
The number of matches is dependent on the genetic diversity of the genus/ species for the target organism.

### Predicting a base line level for contaminat detection.
Overall distribition of Final.Guess values.  Final.Guess is the proprotion of the total number of aligned reads to the number of a reads assinged to a genome in the reference database.
```{r echo=FALSE, message=FALSE}
qplot(x = Final.Guess, data = single_matches, geom= "bar") + scale_x_log10() + theme_bw()
```
The 90 % of the hits have a Final.Guess values of less than `r quantile(single_matches$Final.Guess, probs= 0.90)`.  

```{r echo=FALSE, message=FALSE}
single_matches$match <- factor(single_matches$match, levels = c("exact", "species", "genus","family","order","class", "phylum","no match"))
```
The proportion of the values for Final.Guess is dependent on the match level and the genus of the target organims.  

First two provide evidence regarding the taxonomic limit to which the method is able to identify contaminants
Use this first part to establish a baseline for the noise level - at what final guess cutoff are most if not all not exact matches removed  - look at by genus and size

```{r echo=FALSE, message=FALSE, fig.width=12}
single_matches$match <- factor(single_matches$match, levels = c("exact", "species", "genus","family","order","class", "phylum"))
sim_quant <- ddply(single_matches, .(genus,match,size),summarize, p90 = quantile(Final.Guess, probs=0.9))
ggplot(sim_quant) + geom_line(aes(x = as.numeric(match), y = p90, color = genus)) + scale_y_log10() + scale_x_continuous(breaks = 1:length(levels(sim_quant$match)), labels = levels(sim_quant$match)) + labs(y = "Final.Guess value 90th Percentile", x = "Shared Taxonomic Level with Match") + facet_wrap(~size) + theme_bw()
```

### Sensitivity
```{r echo=FALSE, message=FALSE}
sim_unique_counts <- ddply(contam_matches, .(org1_tid, size), summarize, count = length(unique(match_tid)))
sim_unique_counts$name <- single_matches$name[match(sim_unique_counts$org1_tid, single_matches$org_tid)]
sim_unique_counts$genus <- single_matches$genus[match(sim_unique_counts$org1_tid, single_matches$org_tid)]

ggplot(sim_unique_counts) + 
  geom_boxplot(aes(x = size, y = count), color = "grey") +
  geom_point(aes(x = size, y = count, color = name), size = 4) + 
  geom_line(aes(x = as.numeric(size), y = count, color = name)) +
  labs(x = "Read Size (bp)", y = "Number of hits to unique organisms", color = "Organism")+
  theme_bw()
```
### Observations: 
Between 50 and 200 unique organism hits for each of the dataset combinations.  The difference in the number of unique matches has a much larger decrease compared to single organisms.  
Questions:  
1. can ask similar questions to single organisms   
2. how do the unique matches compare for single and contaminanted datasets.    
Note- that the contaminated dataset counts are based on the unqiue matches for 64 datasets, 6 contaminants and 9 mixtures.  


#### LOD by organism and contaminant
```{r echo=FALSE, message=FALSE}
sim_LOD <- ddply(.data=contam_matches[grep("org2",contam_matches$match),],
                 .variables=.(size, org1_tid, org2_tid, org2_match), 
                 summarize, LOD = min(prop2))
sim_LOD$match <- factor(sim_LOD$org2_match, levels = c("exact", "species", "genus","family","order","class", "phylum"))
sim_LOD$name <- single_matches$name[match(sim_LOD$org1_tid, single_matches$org_tid)]
sim_LOD$genus <- single_matches$genus[match(sim_LOD$org1_tid, single_matches$org_tid)]
sim_LOD <- join(sim_LOD, org_taxa_share)
```
Limit of detection is defined as the proportion of contaminants with the lowest proportion.  The contaminant proportion is representative of the proprotion of the sample and not the proportion of reads.


```{r }
#creating baseline dataset for org1 org2 pairs
#base line defined as the max Final.Guess value in the simulated dataset for org1 genus as the shared taxa level
org_taxa_share$genus <- single_matches$genus[match(org_taxa_share$org1_tid, single_matches$org_tid)]

org_share_base <- join(org_taxa_share,baseline, type="inner")

sim_LOD$genus <- single_matches$genus[match(sim_LOD$org1_tid, single_matches$org_tid)]

org_share_base$org1_tid <- factor(org_share_base$org1_tid)
org_share_base$org2_tid <- factor(org_share_base$org2_tid)
ggplot(org_share_base) + 
  #geom_point(aes(x = 1, y = median, color = match), shape = 3, size = 3) +
  #geom_linerange(aes(x = size,ymax = max, ymin = min ), color = "grey") +
  geom_hline(aes(yintercept = median, color = match)) +
  geom_point(data = contam_matches[grep("org2", contam_matches$match),], 
             aes(x = size, y = prop2, color = org2_match), position = position_dodge(width=1)) + 
  scale_y_log10() + 
  #scale_x_continuous(breaks = 1:length(levels(sim_quant$match)), labels = levels(sim_quant$match)) + 
  labs(y = "Final.Guess value 90th Percentile", x = "Shared Taxonomic Level with Match") + 
  facet_grid(org1_tid~org2_tid) + 
  theme_bw()


ggplot(sim_LOD) + 
  geom_point(aes(x = org2_tid, y = LOD, color = org2_tid)) + 
  geom_point(aes(x = match, y = median)) +
  geom_linerange(aes(x = match,ymax = max, ymin = min )) +
  scale_y_log10() + 
#  #scale_x_continuous(breaks = 1:length(levels(sim_quant$match)), labels = levels(sim_quant$match)) + 
 # labs(y = "Final.Guess value 90th Percentile", x = "Shared Taxonomic Level with Match") + 
  facet_grid(size~genus) + 
  theme_bw()
```
Matches at any level to the contaminant genome.

```{r message=FALSE, fig.height=6, fig.width=18}
ggplot(sim_LOD) + 
  geom_point(aes(x = org1_tid, y= LOD, color = org2_match),alpha = 0.75, position = position_dodge(width = 0.5), size = 3) +
  geom_line(aes(x = org1_tid, y = LOD)) +
  labs(linetype = "Read Size (bp)", x = "Match Level") + 
  scale_y_log10() + 
  theme_bw() +
  theme(axis.text.x=element_text(angle=-90)) +
  facet_grid(size~org2_tid, scale = "free")
```
```{r echo=FALSE, message=FALSE}
LOD_table <-dcast(sim_LOD,org2_tid*org1_tid~org2_match*size, value.var = "LOD", fill= "")
```
```{r results='asis', echo=FALSE}
 library(xtable)
  print(xtable(LOD_table),type='html')
```

Observations: For a number of combinations the limit of detection is lower for 75 bp compared to 250 bp simulated datasets.  Need to look into the data to make sure this is not due to a bug in the code.


number of unique hit by read size
	how do the number of unqiue hits compare to the sum of the unique hits for the individual organisms?
LOD for exact matches
	how do the LODs compare within target organisms and among contaminants
	x = target, y = contaminant ????
	LOD by target and contaminant pair
	how do the LODs compare the the baseline noise levels 

# Conclusions
Suitablility of the methods for characterizing target materials
What are the next steps

# References
1.  Coursey, B. Framework for a Biothreat Field Response Mission Capability Framework for a Biothreat Field Response Mission Capability. 2011.
2.	ASTM, Standard Guide for operational guidelines for initial response to a suspected biothreat agent. ASTM International, 2008.
3.	Budowle, B., et al., Criteria for validation of methods in microbial forensics. Applied and environmental microbiology, 2008. 74: p. 5599-607.
4.	Coates, S.G., S.L. Brunelle, and M.G. Davenport, Development of standard method performance requirements for biological threat agent detection methods. Journal of AOAC International, 2011. 94: p. 1328-37.
5.	AOAC, AOAC SMPR 2010 . 002. 2011. p. 1342-1346.
6.	AOAC, AOAC SMPR 2010 . 001. 2011. p. 1338-1341.
7.	AOAC, AOAC SMPR 2010 . 003. 2011. p. 1347-1351.
8.	Shrestha, P.M., et al., When Is a Microbial Culture “ Pure ”? Persistent Cryptic Contaminant Escapes Detection Even with Deep Genome Sequencing. mBio, 2013. 4(3): p. e300591-12.
9.	Marron, A.O., M. Akam, and G. Walker, A Duplex PCR-Based Assay for Measuring the Amount of Bacterial Contamination in a Nucleic Acid Extract from a Culture of Free-Living Protists. PloS one, 2013. 8: p. e61732.
10.	Schmieder, R. and R. Edwards, Fast identification and removal of sequence contamination from genomic and metagenomic datasets. PloS one, 2011. 6: p. e17288.
11.	Zhou, Q., et al., QC-Chain: Fast and Holistic Quality Control Method for Next-Generation Sequencing Data. PLoS ONE, 2013. 8: p. e60234.
12.	Francis, O.E., et al., Pathoscope: Species identification and strain attribution with unassembled sequencing data. Genome research, 2013.
13.	Huang, W., et al., ART: a next-generation sequencing read simulator. Bioinformatics (Oxford, England), 2012. 28: p. 593-4.
14.	R Core Team. R: A language and environment for statistical computing. 2013, R Foundation for Statistical Computing: Vienna, Austria.
15.	Fukushima, M., K. Kakinuma, and R. Kawaguchi, Phylogenetic Analysis of Salmonella , Shigella , and Escherichia coli Strains on the Basis of the gyrB Gene Sequence Phylogenetic Analysis of Salmonella , Shigella , and Escherichia coli Strains on the Basis of the gyrB Gene Sequence. Journal of Clinical Microbiology, 2002. 40(8): p. 2779-2785.

# Acknowladgements
The authors would like to thanks Dr. Steven Lund for his assistance in developing the study.  The Department of Homeland Security (DHS) Science and Technology Directorate supported this work under the Interagency Agreement HSHQPM-12-X-00078 with the National Institute of Standards and Technology (NIST).  Opinions expressed in this paper are the authors’ and do not necessarily reflect the policies and views of DHS, NIST, or affiliated venues.  Certain commercial equipment, instruments, or materials are identified in this paper in order to specify the experimental procedure adequately.  Such identification is not intended to imply recommendations or endorsement by NIST, nor is it intended to imply that the materials or equipment identified are necessarily the best available for the purpose.  Official contribution of NIST; not subject to copyrights in USA.